# RFC 9309: Robots Exclusion Protocol

https://www.rfc-editor.org/rfc/rfc9309.html

# Google Robots.txt Parser and Matcher Library

https://github.com/google/robotstxt

1. Get the list of urls to crawl
2. Loop over urls (parallel with max threads?)
3. Read robots.txt
4. start crawling
